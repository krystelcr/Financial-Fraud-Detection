{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which insights did you gain from your EDA? \n",
    "- Fraudulent transactions are rare compared to non-fraudulent ones, making the dataset highly imbalanced\n",
    "- Fraud occurs mostly in 'TRANSFER' and 'CASH_OUT' transactions, suggesting targeted fraudulent activities\n",
    "- The 'amount' and 'oldbalanceOrg' columns are highly correlated, indicating accounts are fully drained\n",
    "- Destination accounts remain untouched (oldbalanceDest == newbalanceDest), suggesting fake accounts\n",
    "- Fraudulent high value transactions appear but dosent surpass 10000000 \n",
    "\n",
    "# How did you determine which columns to drop or keep? If your EDA informed this process, explain which insights you used to determine which columns were not needed. \n",
    "- Dropped 'nameOrig' and 'nameDest' since they were identifiers and didn't contribute to fraud detection\n",
    "- Dropped 'isFlaggedFraud' because it we are making models to predict fraud\n",
    "- Kept 'type' but applied one-hot encoding to use it in machine learning models\n",
    "\n",
    "# Which hyperparameter tuning strategy did you use? Grid-search or random-search? Why? \n",
    "I used Grid-search for kNN because the main hyperparameter is the number of neighbors, since there arent many possible values it's fine to try them\n",
    "\n",
    "# How did your model's performance change after discovering optimal hyperparameters? \n",
    "Didnt test kNN before tuning the hyperparameters, but I assume it improved significantly increasing recall and F1-score\n",
    "\n",
    "# What was your final F1 Score? \n",
    "Logistic Regression: 0.56\n",
    "Naive Bayes: 0.02\n",
    "k-Nearest Neighbors: 0.68\n",
    "k-Nearest Neighbors best performing model, most balanced from the three in regards to precision and recall\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
